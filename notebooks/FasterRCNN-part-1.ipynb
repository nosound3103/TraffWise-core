{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be568112",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T10:09:58.427419Z",
     "iopub.status.busy": "2025-03-14T10:09:58.427219Z",
     "iopub.status.idle": "2025-03-14T10:09:58.430807Z",
     "shell.execute_reply": "2025-03-14T10:09:58.430267Z"
    },
    "papermill": {
     "duration": 0.00781,
     "end_time": "2025-03-14T10:09:58.431974",
     "exception": false,
     "start_time": "2025-03-14T10:09:58.424164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.copy(\"/kaggle/input/vehicle-detection-v1/training_log.csv\", \"/kaggle/working/training_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e5eb271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T10:09:58.437387Z",
     "iopub.status.busy": "2025-03-14T10:09:58.437180Z",
     "iopub.status.idle": "2025-03-14T10:09:58.445692Z",
     "shell.execute_reply": "2025-03-14T10:09:58.445061Z"
    },
    "papermill": {
     "duration": 0.012772,
     "end_time": "2025-03-14T10:09:58.446903",
     "exception": false,
     "start_time": "2025-03-14T10:09:58.434131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ddp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ddp.py\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "from typing import Dict, List, Tuple\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torch.optim import AdamW, SGD\n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "from torchvision.models.detection.backbone_utils import BackboneWithFPN\n",
    "from torchvision.models import mobilenet_v3_small\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "import math\n",
    "import torchvision.models as models\n",
    "from torchvision.models import MobileNet_V3_Small_Weights\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Import DDP related modules\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.distributed as dist\n",
    "import functools\n",
    "\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(640, 640)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class_to_idx = {\n",
    "    \"bus\": 0, \"car\": 1, \"motorbike\": 2, \"truck\": 3,\n",
    "}\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 root_dir,\n",
    "                 split=\"train\",\n",
    "                 class_to_idx=class_to_idx,\n",
    "                 transform=data_transform):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = class_to_idx if class_to_idx else {}\n",
    "\n",
    "        self.image_dir = os.path.join(root_dir, \"images\", split)\n",
    "        self.label_dir = os.path.join(root_dir, \"labels\", split)\n",
    "\n",
    "        self.image_files = [f for f in os.listdir(\n",
    "            self.image_dir) if f.endswith(\".jpg\") or f.endswith(\".png\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_filename = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_filename)\n",
    "\n",
    "        img_name, _ = os.path.splitext(img_filename)\n",
    "        label_path = os.path.join(self.label_dir, img_name + \".txt\")\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        original_width, original_height = img.size\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, \"r\") as f:\n",
    "                for line in f.readlines():\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) < 5:\n",
    "                        continue\n",
    "\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center, y_center, w, h = map(float, parts[1:])\n",
    "\n",
    "                    xmin = (x_center - w / 2) * original_width\n",
    "                    ymin = (y_center - h / 2) * original_height\n",
    "                    xmax = (x_center + w / 2) * original_width\n",
    "                    ymax = (y_center + h / 2) * original_height\n",
    "\n",
    "                    if xmin < xmax and ymin < ymax:\n",
    "                        boxes.append([xmin, ymin, xmax, ymax])\n",
    "                        labels.append(class_id + 1)\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "        if len(boxes) == 0:\n",
    "            boxes = torch.zeros((1, 4), dtype=torch.float32)\n",
    "            labels = torch.zeros((1,), dtype=torch.int64)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        new_width, new_height = 640, 640\n",
    "        scale_x = new_width / original_width\n",
    "        scale_y = new_height / original_height\n",
    "\n",
    "        boxes[:, [0, 2]] *= scale_x\n",
    "        boxes[:, [1, 3]] *= scale_y\n",
    "        target[\"boxes\"] = boxes\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "class CustomRCNNTransform(GeneralizedRCNNTransform):\n",
    "    def __init__(self):\n",
    "        super().__init__(min_size=640, max_size=640, image_mean=[\n",
    "            0.485, 0.456, 0.406], image_std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    def resize(self, image, target):\n",
    "        image = F.resize(image, [640, 640])\n",
    "\n",
    "        if target is not None and \"boxes\" in target:\n",
    "            w_old, h_old = image.shape[-1], image.shape[-2]\n",
    "            w_new, h_new = 640, 640\n",
    "            scale_w = w_new / w_old\n",
    "            scale_h = h_new / h_old\n",
    "            target[\"boxes\"][:, [0, 2]] *= scale_w\n",
    "            target[\"boxes\"][:, [1, 3]] *= scale_h\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class FRCNN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_classes,\n",
    "                 pretrained=MobileNet_V3_Small_Weights.DEFAULT):\n",
    "        super(FRCNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.backbone = self.get_backbone(pretrained)\n",
    "\n",
    "        self.anchor_sizes = (32, 64, 128, 256)\n",
    "        self.aspect_ratios = ((0.5, 1.0, 2.0),) * len(self.anchor_sizes)\n",
    "\n",
    "        self.anchor_generator = AnchorGenerator(\n",
    "            sizes=self.anchor_sizes,\n",
    "            aspect_ratios=self.aspect_ratios\n",
    "        )\n",
    "\n",
    "        self.model = FasterRCNN(\n",
    "            backbone=self.backbone,\n",
    "            num_classes=num_classes,\n",
    "            rpn_anchor_generator=self.anchor_generator\n",
    "        )\n",
    "\n",
    "        self.model.transform = CustomRCNNTransform()\n",
    "\n",
    "    def get_backbone(self, pretrained):\n",
    "        backbone = mobilenet_v3_small(weights=pretrained).features\n",
    "        \"\"\"Chọn lớp 2, 7, 12 trong backbone vì:\n",
    "        - Cung cấp đặc trưng ở các mức độ phân giải và độ sâu khác nhau\n",
    "        - Có số kênh đầu ra (24, 48, 576) phù hợp với thiết kế của FPN trong mã của bạn\n",
    "        - Phân bố đều trong cấu trúc của MobileNetV3-Small để tối ưu hóa việc phát hiện đối tượng ở nhiều tỷ lệ\"\"\"\n",
    "        return_layers = {'2': '0', '7': '1', '12': '2'}\n",
    "        in_channels = [24, 48, 576]\n",
    "\n",
    "        backbone.out_channels = 64\n",
    "        fpn = BackboneWithFPN(\n",
    "            backbone=backbone,\n",
    "            return_layers=return_layers,\n",
    "            in_channels_list=in_channels,\n",
    "            out_channels=64\n",
    "        )\n",
    "\n",
    "        return fpn\n",
    "\n",
    "    def forward(self, images, targets=None):\n",
    "        if self.training:\n",
    "            if targets is None:\n",
    "                raise ValueError(\"In training mode, targets should be passed\")\n",
    "            return self.model(images, targets)\n",
    "        else:\n",
    "            return self.model(images)\n",
    "\n",
    "\n",
    "\n",
    "# Define a custom collate function outside other functions\n",
    "def detection_collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "# Training loop with DDP - defined as top-level function\n",
    "def train_one_epoch(model, optimizer, train_loader, device, rank):\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    total_loc_loss = 0.0  # Localization Loss\n",
    "    total_cls_loss = 0.0  # Classification Loss\n",
    "    \n",
    "    if rank == 0:\n",
    "        progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    else:\n",
    "        progress_bar = train_loader\n",
    "    \n",
    "    for images, targets in progress_bar:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "        \n",
    "        # Trích xuất các thành phần loss\n",
    "        loc_loss = loss_dict[\"loss_box_reg\"] + loss_dict.get(\"loss_rpn_box_reg\", 0.0)  # Localization Loss\n",
    "        cls_loss = loss_dict[\"loss_classifier\"]  # Classification Loss\n",
    "        total_loss = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        total_train_loss += total_loss.item()\n",
    "        total_loc_loss += loc_loss.item()\n",
    "        total_cls_loss += cls_loss.item()\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Tính trung bình qua tất cả batch\n",
    "    train_loss = total_train_loss / len(train_loader)\n",
    "    train_loc_loss = total_loc_loss / len(train_loader)\n",
    "    train_cls_loss = total_cls_loss / len(train_loader)\n",
    "    \n",
    "    # Đồng bộ hóa giữa các GPU\n",
    "    train_loss_tensor = torch.tensor(train_loss, device=device)\n",
    "    train_loc_loss_tensor = torch.tensor(train_loc_loss, device=device)\n",
    "    train_cls_loss_tensor = torch.tensor(train_cls_loss, device=device)\n",
    "    dist.all_reduce(train_loss_tensor, op=dist.ReduceOp.SUM)\n",
    "    dist.all_reduce(train_loc_loss_tensor, op=dist.ReduceOp.SUM)\n",
    "    dist.all_reduce(train_cls_loss_tensor, op=dist.ReduceOp.SUM)\n",
    "    \n",
    "    world_size = dist.get_world_size()\n",
    "    train_loss = train_loss_tensor.item() / world_size\n",
    "    train_loc_loss = train_loc_loss_tensor.item() / world_size\n",
    "    train_cls_loss = train_cls_loss_tensor.item() / world_size\n",
    "    \n",
    "    return train_loss, train_loc_loss, train_cls_loss\n",
    "\n",
    "# Evaluation function - unchanged\n",
    "def evaluate(model, val_loader, device, rank):\n",
    "    model.eval()\n",
    "    metric = MeanAveragePrecision(class_metrics=True, extended_summary=True).to(device)\n",
    "    total_val_loss = 0.0\n",
    "    total_loc_loss = 0.0  # Localization Loss\n",
    "    total_cls_loss = 0.0  # Classification Loss\n",
    "    \n",
    "    if rank == 0:\n",
    "        progress_bar = tqdm(val_loader, desc=\"Evaluating\", leave=False)\n",
    "    else:\n",
    "        progress_bar = val_loader\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in progress_bar:\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            model.train()  # Temporarily enable training mode for loss\n",
    "            loss_dict = model(images, targets)\n",
    "            \n",
    "            # Trích xuất các thành phần loss\n",
    "            loc_loss = loss_dict[\"loss_box_reg\"] + loss_dict.get(\"loss_rpn_box_reg\", 0.0)  # Localization Loss\n",
    "            cls_loss = loss_dict[\"loss_classifier\"]  # Classification Loss\n",
    "            total_loss = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            total_val_loss += total_loss.item()\n",
    "            total_loc_loss += loc_loss.item()\n",
    "            total_cls_loss += cls_loss.item()\n",
    "            \n",
    "            model.eval()  # Back to eval mode\n",
    "            outputs = model(images)\n",
    "            preds = [\n",
    "                {\"boxes\": output[\"boxes\"], \"scores\": output[\"scores\"], \"labels\": output[\"labels\"]}\n",
    "                for output in outputs\n",
    "            ]\n",
    "            metric.update(preds, targets)\n",
    "\n",
    "    # Tính toán kết quả từ metric\n",
    "    results = metric.compute()\n",
    "    map50 = torch.tensor(results[\"map_50\"].item(), device=device)\n",
    "    map95 = torch.tensor(results[\"map\"].item(), device=device)\n",
    "    map95_per_class = results[\"map_per_class\"][results[\"map_per_class\"] != -1].tolist()\n",
    "    \n",
    "    # Trích xuất precision và recall từng class\n",
    "    iou_idx = 0  # IoU=0.5\n",
    "    num_classes = len(map95_per_class)\n",
    "    precision_tensor = results[\"precision\"][iou_idx]  # Shape: (R, K, A, M)\n",
    "    recall_tensor = results[\"recall\"][iou_idx]  # Shape: (K, A, M)\n",
    "    \n",
    "    precision_per_class = [precision_tensor[:, cls, 0, :].mean().item() if not torch.isnan(precision_tensor[:, cls, 0, :]).all() else 0.0 for cls in range(num_classes)]\n",
    "    recall_per_class = [recall_tensor[cls, 0, :].mean().item() if not torch.isnan(recall_tensor[cls, 0, :]).all() else 0.0 for cls in range(num_classes)]\n",
    "    \n",
    "    precision_avg = sum(precision_per_class) / len(precision_per_class) if precision_per_class else 0.0\n",
    "    recall_avg = sum(recall_per_class) / len(recall_per_class) if recall_per_class else 0.0\n",
    "    \n",
    "    # Tính trung bình loss\n",
    "    val_loss = total_val_loss / len(val_loader)\n",
    "    val_loc_loss = total_loc_loss / len(val_loader)\n",
    "    val_cls_loss = total_cls_loss / len(val_loader)\n",
    "    \n",
    "    # Đồng bộ hóa giữa các GPU\n",
    "    dist.all_reduce(map50, op=dist.ReduceOp.SUM)\n",
    "    dist.all_reduce(map95, op=dist.ReduceOp.SUM)\n",
    "    dist.all_reduce(torch.tensor(val_loss, device=device), op=dist.ReduceOp.SUM)\n",
    "    dist.all_reduce(torch.tensor(val_loc_loss, device=device), op=dist.ReduceOp.SUM)\n",
    "    dist.all_reduce(torch.tensor(val_cls_loss, device=device), op=dist.ReduceOp.SUM)\n",
    "    \n",
    "    map95_per_class_tensor = torch.tensor(map95_per_class, device=device)\n",
    "    precision_per_class_tensor = torch.tensor(precision_per_class, device=device)\n",
    "    recall_per_class_tensor = torch.tensor(recall_per_class, device=device)\n",
    "    dist.all_reduce(map95_per_class_tensor, op=dist.ReduceOp.SUM)\n",
    "    dist.all_reduce(precision_per_class_tensor, op=dist.ReduceOp.SUM)\n",
    "    dist.all_reduce(recall_per_class_tensor, op=dist.ReduceOp.SUM)\n",
    "    \n",
    "    world_size = dist.get_world_size()\n",
    "    map50 = map50.item() / world_size\n",
    "    map95 = map95.item() / world_size\n",
    "    val_loss = val_loss / world_size\n",
    "    val_loc_loss = val_loc_loss / world_size\n",
    "    val_cls_loss = val_cls_loss / world_size\n",
    "    map95_per_class = (map95_per_class_tensor / world_size).tolist()\n",
    "    precision_per_class = (precision_per_class_tensor / world_size).tolist()\n",
    "    recall_per_class = (recall_per_class_tensor / world_size).tolist()\n",
    "    precision_avg = precision_avg / world_size\n",
    "    recall_avg = recall_avg / world_size\n",
    "\n",
    "    return map50, map95, val_loss, map95_per_class, precision_per_class, recall_per_class, precision_avg, recall_avg, val_loc_loss, val_cls_loss\n",
    "\n",
    "# Main DDP training function with ReduceLROnPlateau\n",
    "def train_ddp(rank, world_size, data_dir, num_classes, num_epochs, batch_size, lr, resume_from):\n",
    "    # Setup DDP\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    \n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "    torch.cuda.set_device(device)\n",
    "\n",
    "    # Initialize datasets and samplers\n",
    "    train_dataset = CustomDataset(data_dir)\n",
    "    val_dataset = CustomDataset(data_dir, split=\"val\")\n",
    "\n",
    "    train_sampler = DistributedSampler(\n",
    "        train_dataset, \n",
    "        num_replicas=world_size, \n",
    "        rank=rank,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_sampler = DistributedSampler(\n",
    "        val_dataset, \n",
    "        num_replicas=world_size, \n",
    "        rank=rank,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=train_sampler,\n",
    "        num_workers=2,\n",
    "        collate_fn=detection_collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=val_sampler,\n",
    "        num_workers=2,\n",
    "        collate_fn=detection_collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Create model\n",
    "    model = FRCNN(num_classes=num_classes)\n",
    "    model = model.to(device)\n",
    "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[rank], output_device=rank)\n",
    "\n",
    "    # Create optimizer\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=lr,               # Initial learning rate (passed as argument)\n",
    "        betas=(0.85, 0.999), # Adjusted beta1 for DDP\n",
    "        weight_decay=0.01,\n",
    "        eps=1e-8\n",
    "    )\n",
    "    \n",
    "    # Create ReduceLROnPlateau scheduler (only on rank 0)\n",
    "    scheduler = None\n",
    "    if rank == 0:\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',       # Minimize validation loss\n",
    "            factor=0.1,       # Reduce lr by 10x\n",
    "            patience=5,       # Wait 5 epochs\n",
    "            threshold=0.0001, # Minimum improvement\n",
    "            min_lr=1e-6,      # Minimum learning rate\n",
    "            verbose=True      # Print updates\n",
    "        )\n",
    "\n",
    "    # Load checkpoint if resuming\n",
    "    best_map95 = 0\n",
    "    start_epoch = 1\n",
    "    \n",
    "    if resume_from and os.path.exists(resume_from):\n",
    "        map_location = {'cuda:%d' % 0: 'cuda:%d' % rank}\n",
    "        checkpoint = torch.load(resume_from, map_location=map_location, weights_only=True)\n",
    "        model.module.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        best_map95 = checkpoint.get(\"best_map95\", 0)\n",
    "        if rank == 0 and \"scheduler_state_dict\" in checkpoint:\n",
    "            scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "        if rank == 0:\n",
    "            print(f\"Resuming from epoch {start_epoch} with best map95: {best_map95:.4f}\")\n",
    "\n",
    "    \n",
    "    # Định nghĩa tên class\n",
    "    class_names = [\"bus\", \"car\", \"motorbike\", \"truck\"]\n",
    "\n",
    "    # CSV logging chỉ trên rank 0\n",
    "    csv_filename = \"training_log.csv\"\n",
    "    if rank == 0:\n",
    "        if not os.path.exists(csv_filename) or not resume_from:\n",
    "            with open(csv_filename, \"w\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                headers = [\"epoch\", \"train_loss\", \"train_loc_loss\", \"train_cls_loss\", \"val_loss\", \"val_loc_loss\", \"val_cls_loss\", \n",
    "                           \"mAP50\", \"mAP95\", \"precision_avg\", \"recall_avg\"]\n",
    "                for cls in class_names:\n",
    "                    headers.append(f\"mAP95_{cls}\")\n",
    "                    headers.append(f\"precision_{cls}\")\n",
    "                    headers.append(f\"recall_{cls}\")\n",
    "                headers.append(\"learning_rate\")\n",
    "                writer.writerow(headers)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(start_epoch, num_epochs + 1):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        val_sampler.set_epoch(epoch)\n",
    "        \n",
    "        train_loss, train_loc_loss, train_cls_loss = train_one_epoch(model, optimizer, train_loader, device, rank)\n",
    "        map50, map95, val_loss, map95_per_class, precision_per_class, recall_per_class, precision_avg, recall_avg, val_loc_loss, val_cls_loss = evaluate(model, val_loader, device, rank)\n",
    "        \n",
    "        if rank == 0 and scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        if rank == 0:\n",
    "            checkpoint = {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": model.module.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"best_map95\": best_map95,\n",
    "                \"scheduler_state_dict\": scheduler.state_dict() if scheduler else None\n",
    "            }\n",
    "            torch.save(checkpoint, \"last_model.pt\")\n",
    "            \n",
    "            if map95 > best_map95:\n",
    "                best_map95 = map95\n",
    "                torch.save(checkpoint, \"best_model.pt\")\n",
    "            \n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            with open(csv_filename, \"a\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                row = [epoch, train_loss, train_loc_loss, train_cls_loss, val_loss, val_loc_loss, val_cls_loss, \n",
    "                       map50, map95, precision_avg, recall_avg]\n",
    "                row.extend(map95_per_class)\n",
    "                row.extend(precision_per_class)\n",
    "                row.extend(recall_per_class)\n",
    "                row.append(current_lr)\n",
    "                writer.writerow(row)\n",
    "            \n",
    "            print(f\"[Epoch {epoch}/{num_epochs}] \"\n",
    "                  f\"Train Loss: {train_loss:.4f} (Loc: {train_loc_loss:.4f}, Cls: {train_cls_loss:.4f}) | \"\n",
    "                  f\"Val Loss: {val_loss:.4f} (Loc: {val_loc_loss:.4f}, Cls: {val_cls_loss:.4f}) | \"\n",
    "                  f\"mAP@50: {map50:.4f} | mAP@50:95: {map95:.4f} | \"\n",
    "                  f\"Precision (Avg): {precision_avg:.4f} | Recall (Avg): {recall_avg:.4f} | LR: {current_lr:.6f}\")\n",
    "            for cls, m95, prec, rec in zip(class_names, map95_per_class, precision_per_class, recall_per_class):\n",
    "                print(f\"  {cls}: mAP@50:95: {m95:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f}\")\n",
    "    \n",
    "    dist.destroy_process_group()\n",
    "\n",
    "\n",
    "# Single GPU training function\n",
    "def train_single_gpu(data_dir, num_classes, num_epochs, batch_size, lr, resume_from=None):\n",
    "    model = FRCNN(num_classes = num_classes).to(device)\n",
    "    optimizer = SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=0.0005)\n",
    "    \n",
    "    # best_val_loss = float(\"inf\")  # Đổi từ best_loss sang best_val_loss\n",
    "    best_map95 = 0\n",
    "    start_epoch = 1\n",
    "    \n",
    "    if resume_from and os.path.exists(resume_from):\n",
    "        map_location = {'cuda:%d' % 0: 'cuda:%d' % rank}\n",
    "        checkpoint = torch.load(resume_from, map_location=map_location, weights_only=True)\n",
    "        model.module.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        # best_map95 = checkpoint.get(\"best_map95\", 0) \n",
    "        print(f\"Resuming from epoch {start_epoch} with best map95: {best_map95:.4f}\")\n",
    "    \n",
    "    # Sửa header của CSV để thêm val_loss\n",
    "    csv_filename = \"training_log.csv\"\n",
    "    with open(csv_filename, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"epoch\", \"train_loss\", \"val_loss\", \"mAP50\", \"mAP95\"])\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs + 1):\n",
    "        # Train\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "        for images, targets in progress_bar:\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            loss_dict = model(images, targets)\n",
    "            loss = sum(loss for loss in loss_dict.values())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "        \n",
    "        train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # Evaluate với validation loss\n",
    "        model.eval()\n",
    "        metric = MeanAveragePrecision().to(device)\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, targets in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n",
    "                images = [img.to(device) for img in images]\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                # Tính validation loss\n",
    "                model.train()  # Tạm thời bật training mode để tính loss\n",
    "                loss_dict = model(images, targets)\n",
    "                loss = sum(loss for loss in loss_dict.values())\n",
    "                total_val_loss += loss.item()\n",
    "                model.eval()  # Quay lại eval mode\n",
    "                \n",
    "                outputs = model(images)\n",
    "                preds = [\n",
    "                    {\"boxes\": output[\"boxes\"], \"scores\": output[\"scores\"], \"labels\": output[\"labels\"]}\n",
    "                    for output in outputs\n",
    "                ]\n",
    "                metric.update(preds, targets)\n",
    "        \n",
    "        val_loss = total_val_loss / len(val_loader)\n",
    "        results = metric.compute()\n",
    "        map50 = results[\"map_50\"].item()\n",
    "        map95 = results[\"map\"].item()\n",
    "        \n",
    "        # Save checkpoints\n",
    "        torch.save({\n",
    "                    \"epoch\": epoch,\n",
    "                    \"model_state_dict\": model.module.state_dict(),\n",
    "                    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    \"best_map95\": best_map95# Sửa key\n",
    "                }, \"last_model.pt\")\n",
    "        \n",
    "        if map95 > best_map95:\n",
    "                    best_map95 = map95\n",
    "                    torch.save({\n",
    "                        \"epoch\": epoch,\n",
    "                        \"model_state_dict\": model.module.state_dict(),\n",
    "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                        \"best_map95\": best_map95\n",
    "                    }, \"best_model.pt\")\n",
    "        \n",
    "        # Log cả train_loss và val_loss\n",
    "        with open(csv_filename, \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([epoch, train_loss, val_loss, map50, map95])\n",
    "        \n",
    "        print(f\"[Epoch {epoch}/{num_epochs}] Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | mAP@50: {map50:.4f} | mAP@50:95: {map95:.4f}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Set params\n",
    "    world_size = torch.cuda.device_count()  # Number of GPUs available\n",
    "    data_dir = '/kaggle/input/vehicle-detection-v1/combination/combination'\n",
    "    num_classes = 5\n",
    "    num_epochs = 50\n",
    "    batch_size = 64\n",
    "    lr = 1e-4\n",
    "    resume_from = None\n",
    "    \n",
    "    if world_size > 1:\n",
    "        print(f\"Training with {world_size} GPUs using DDP\")\n",
    "        # Adjust batch size per GPU\n",
    "        batch_size_per_gpu = batch_size // world_size\n",
    "        \n",
    "        # Use spawn method for starting processes\n",
    "        mp.spawn(\n",
    "            train_ddp,\n",
    "            args=(world_size, data_dir, num_classes, num_epochs, batch_size_per_gpu, lr, resume_from),\n",
    "            nprocs=world_size,\n",
    "            join=True\n",
    "        )\n",
    "    else:\n",
    "        print(\"Only one GPU detected, training without DDP\")\n",
    "        train_single_gpu(data_dir, num_classes, num_epochs, batch_size, lr, resume_from)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure proper process initialization for CUDA\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48683dcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T10:09:58.451455Z",
     "iopub.status.busy": "2025-03-14T10:09:58.451259Z",
     "iopub.status.idle": "2025-03-14T15:21:49.629887Z",
     "shell.execute_reply": "2025-03-14T15:21:49.628774Z"
    },
    "papermill": {
     "duration": 18711.18271,
     "end_time": "2025-03-14T15:21:49.631609",
     "exception": false,
     "start_time": "2025-03-14T10:09:58.448899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 2 GPUs using DDP\r\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\r\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\r\n",
      "100%|██████████████████████████████████████| 9.83M/9.83M [00:00<00:00, 89.1MB/s]\r\n",
      "100%|██████████████████████████████████████| 9.83M/9.83M [00:00<00:00, 85.5MB/s]\r\n",
      "[Epoch 1/50] Train Loss: 0.6962 (Loc: 0.3023, Cls: 0.2228) | Val Loss: 0.2919 (Loc: 0.1669, Cls: 0.1017) | mAP@50: 0.6147 | mAP@50:95: 0.3086 | Precision (Avg): 0.2340 | Recall (Avg): 0.3164 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.2428 | Precision: 0.4478 | Recall: 0.6961\r\n",
      "  car: mAP@50:95: 0.4087 | Precision: 0.5267 | Recall: 0.6095\r\n",
      "  motorbike: mAP@50:95: 0.3481 | Precision: 0.4600 | Recall: 0.5515\r\n",
      "  truck: mAP@50:95: 0.2346 | Precision: 0.4376 | Recall: 0.6742\r\n",
      "[Epoch 2/50] Train Loss: 0.5337 (Loc: 0.3137, Cls: 0.1809) | Val Loss: 0.2504 (Loc: 0.1487, Cls: 0.0848) | mAP@50: 0.7416 | mAP@50:95: 0.4257 | Precision (Avg): 0.2850 | Recall (Avg): 0.3401 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.4089 | Precision: 0.6129 | Recall: 0.7777\r\n",
      "  car: mAP@50:95: 0.5125 | Precision: 0.5865 | Recall: 0.6377\r\n",
      "  motorbike: mAP@50:95: 0.4212 | Precision: 0.5124 | Recall: 0.5827\r\n",
      "  truck: mAP@50:95: 0.3601 | Precision: 0.5684 | Recall: 0.7225\r\n",
      "[Epoch 3/50] Train Loss: 0.4702 (Loc: 0.2831, Cls: 0.1569) | Val Loss: 0.2277 (Loc: 0.1365, Cls: 0.0770) | mAP@50: 0.7897 | mAP@50:95: 0.4843 | Precision (Avg): 0.3035 | Recall (Avg): 0.3488 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.4800 | Precision: 0.6705 | Recall: 0.7949\r\n",
      "  car: mAP@50:95: 0.5580 | Precision: 0.6044 | Recall: 0.6477\r\n",
      "  motorbike: mAP@50:95: 0.4625 | Precision: 0.5351 | Recall: 0.5980\r\n",
      "  truck: mAP@50:95: 0.4368 | Precision: 0.6183 | Recall: 0.7496\r\n",
      "[Epoch 4/50] Train Loss: 0.4349 (Loc: 0.2654, Cls: 0.1438) | Val Loss: 0.2151 (Loc: 0.1309, Cls: 0.0717) | mAP@50: 0.8232 | mAP@50:95: 0.5213 | Precision (Avg): 0.3169 | Recall (Avg): 0.3525 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.5239 | Precision: 0.7047 | Recall: 0.8022\r\n",
      "  car: mAP@50:95: 0.5854 | Precision: 0.6165 | Recall: 0.6532\r\n",
      "  motorbike: mAP@50:95: 0.4924 | Precision: 0.5515 | Recall: 0.6037\r\n",
      "  truck: mAP@50:95: 0.4836 | Precision: 0.6623 | Recall: 0.7607\r\n",
      "[Epoch 5/50] Train Loss: 0.4119 (Loc: 0.2538, Cls: 0.1349) | Val Loss: 0.2042 (Loc: 0.1241, Cls: 0.0685) | mAP@50: 0.8362 | mAP@50:95: 0.5405 | Precision (Avg): 0.3223 | Recall (Avg): 0.3550 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.5318 | Precision: 0.7198 | Recall: 0.8075\r\n",
      "  car: mAP@50:95: 0.6131 | Precision: 0.6229 | Recall: 0.6570\r\n",
      "  motorbike: mAP@50:95: 0.5057 | Precision: 0.5608 | Recall: 0.6122\r\n",
      "  truck: mAP@50:95: 0.5115 | Precision: 0.6748 | Recall: 0.7631\r\n",
      "[Epoch 6/50] Train Loss: 0.3918 (Loc: 0.2432, Cls: 0.1273) | Val Loss: 0.2001 (Loc: 0.1234, Cls: 0.0658) | mAP@50: 0.8454 | mAP@50:95: 0.5465 | Precision (Avg): 0.3254 | Recall (Avg): 0.3573 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.5324 | Precision: 0.7267 | Recall: 0.8143\r\n",
      "  car: mAP@50:95: 0.6093 | Precision: 0.6223 | Recall: 0.6538\r\n",
      "  motorbike: mAP@50:95: 0.5171 | Precision: 0.5647 | Recall: 0.6120\r\n",
      "  truck: mAP@50:95: 0.5273 | Precision: 0.6897 | Recall: 0.7786\r\n",
      "[Epoch 7/50] Train Loss: 0.3768 (Loc: 0.2351, Cls: 0.1218) | Val Loss: 0.1937 (Loc: 0.1190, Cls: 0.0642) | mAP@50: 0.8528 | mAP@50:95: 0.5683 | Precision (Avg): 0.3287 | Recall (Avg): 0.3595 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.5604 | Precision: 0.7349 | Recall: 0.8174\r\n",
      "  car: mAP@50:95: 0.6369 | Precision: 0.6314 | Recall: 0.6603\r\n",
      "  motorbike: mAP@50:95: 0.5365 | Precision: 0.5698 | Recall: 0.6170\r\n",
      "  truck: mAP@50:95: 0.5394 | Precision: 0.6933 | Recall: 0.7812\r\n",
      "[Epoch 8/50] Train Loss: 0.3653 (Loc: 0.2286, Cls: 0.1180) | Val Loss: 0.1909 (Loc: 0.1187, Cls: 0.0621) | mAP@50: 0.8607 | mAP@50:95: 0.5761 | Precision (Avg): 0.3316 | Recall (Avg): 0.3608 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.5640 | Precision: 0.7370 | Recall: 0.8187\r\n",
      "  car: mAP@50:95: 0.6395 | Precision: 0.6383 | Recall: 0.6629\r\n",
      "  motorbike: mAP@50:95: 0.5386 | Precision: 0.5744 | Recall: 0.6196\r\n",
      "  truck: mAP@50:95: 0.5622 | Precision: 0.7033 | Recall: 0.7851\r\n",
      "[Epoch 9/50] Train Loss: 0.3546 (Loc: 0.2228, Cls: 0.1140) | Val Loss: 0.1875 (Loc: 0.1156, Cls: 0.0621) | mAP@50: 0.8655 | mAP@50:95: 0.5835 | Precision (Avg): 0.3338 | Recall (Avg): 0.3615 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.5736 | Precision: 0.7450 | Recall: 0.8228\r\n",
      "  car: mAP@50:95: 0.6501 | Precision: 0.6378 | Recall: 0.6637\r\n",
      "  motorbike: mAP@50:95: 0.5478 | Precision: 0.5815 | Recall: 0.6213\r\n",
      "  truck: mAP@50:95: 0.5625 | Precision: 0.7060 | Recall: 0.7846\r\n",
      "[Epoch 10/50] Train Loss: 0.3475 (Loc: 0.2188, Cls: 0.1114) | Val Loss: 0.1806 (Loc: 0.1117, Cls: 0.0595) | mAP@50: 0.8684 | mAP@50:95: 0.5895 | Precision (Avg): 0.3348 | Recall (Avg): 0.3624 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.5664 | Precision: 0.7486 | Recall: 0.8242\r\n",
      "  car: mAP@50:95: 0.6592 | Precision: 0.6382 | Recall: 0.6633\r\n",
      "  motorbike: mAP@50:95: 0.5578 | Precision: 0.5823 | Recall: 0.6204\r\n",
      "  truck: mAP@50:95: 0.5747 | Precision: 0.7094 | Recall: 0.7914\r\n",
      "[Epoch 11/50] Train Loss: 0.3384 (Loc: 0.2137, Cls: 0.1082) | Val Loss: 0.1795 (Loc: 0.1114, Cls: 0.0590) | mAP@50: 0.8742 | mAP@50:95: 0.6023 | Precision (Avg): 0.3371 | Recall (Avg): 0.3625 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6016 | Precision: 0.7607 | Recall: 0.8277\r\n",
      "  car: mAP@50:95: 0.6670 | Precision: 0.6392 | Recall: 0.6630\r\n",
      "  motorbike: mAP@50:95: 0.5624 | Precision: 0.5845 | Recall: 0.6212\r\n",
      "  truck: mAP@50:95: 0.5783 | Precision: 0.7126 | Recall: 0.7879\r\n",
      "[Epoch 12/50] Train Loss: 0.3323 (Loc: 0.2103, Cls: 0.1060) | Val Loss: 0.1766 (Loc: 0.1095, Cls: 0.0579) | mAP@50: 0.8786 | mAP@50:95: 0.6081 | Precision (Avg): 0.3382 | Recall (Avg): 0.3624 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6035 | Precision: 0.7621 | Recall: 0.8267\r\n",
      "  car: mAP@50:95: 0.6751 | Precision: 0.6433 | Recall: 0.6666\r\n",
      "  motorbike: mAP@50:95: 0.5663 | Precision: 0.5838 | Recall: 0.6250\r\n",
      "  truck: mAP@50:95: 0.5875 | Precision: 0.7167 | Recall: 0.7811\r\n",
      "[Epoch 13/50] Train Loss: 0.3260 (Loc: 0.2072, Cls: 0.1034) | Val Loss: 0.1765 (Loc: 0.1099, Cls: 0.0579) | mAP@50: 0.8813 | mAP@50:95: 0.6104 | Precision (Avg): 0.3399 | Recall (Avg): 0.3626 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6033 | Precision: 0.7637 | Recall: 0.8251\r\n",
      "  car: mAP@50:95: 0.6751 | Precision: 0.6432 | Recall: 0.6648\r\n",
      "  motorbike: mAP@50:95: 0.5666 | Precision: 0.5879 | Recall: 0.6250\r\n",
      "  truck: mAP@50:95: 0.5968 | Precision: 0.7247 | Recall: 0.7857\r\n",
      "[Epoch 14/50] Train Loss: 0.3195 (Loc: 0.2033, Cls: 0.1013) | Val Loss: 0.1720 (Loc: 0.1070, Cls: 0.0564) | mAP@50: 0.8813 | mAP@50:95: 0.6117 | Precision (Avg): 0.3394 | Recall (Avg): 0.3631 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6024 | Precision: 0.7640 | Recall: 0.8299\r\n",
      "  car: mAP@50:95: 0.6807 | Precision: 0.6430 | Recall: 0.6655\r\n",
      "  motorbike: mAP@50:95: 0.5730 | Precision: 0.5888 | Recall: 0.6240\r\n",
      "  truck: mAP@50:95: 0.5908 | Precision: 0.7194 | Recall: 0.7852\r\n",
      "[Epoch 15/50] Train Loss: 0.3146 (Loc: 0.2007, Cls: 0.0995) | Val Loss: 0.1711 (Loc: 0.1061, Cls: 0.0565) | mAP@50: 0.8823 | mAP@50:95: 0.6163 | Precision (Avg): 0.3401 | Recall (Avg): 0.3632 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6112 | Precision: 0.7680 | Recall: 0.8284\r\n",
      "  car: mAP@50:95: 0.6879 | Precision: 0.6467 | Recall: 0.6680\r\n",
      "  motorbike: mAP@50:95: 0.5751 | Precision: 0.5907 | Recall: 0.6253\r\n",
      "  truck: mAP@50:95: 0.5909 | Precision: 0.7158 | Recall: 0.7841\r\n",
      "[Epoch 16/50] Train Loss: 0.3095 (Loc: 0.1980, Cls: 0.0974) | Val Loss: 0.1720 (Loc: 0.1070, Cls: 0.0564) | mAP@50: 0.8856 | mAP@50:95: 0.6202 | Precision (Avg): 0.3413 | Recall (Avg): 0.3623 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6074 | Precision: 0.7688 | Recall: 0.8268\r\n",
      "  car: mAP@50:95: 0.6913 | Precision: 0.6449 | Recall: 0.6661\r\n",
      "  motorbike: mAP@50:95: 0.5825 | Precision: 0.5918 | Recall: 0.6242\r\n",
      "  truck: mAP@50:95: 0.5996 | Precision: 0.7248 | Recall: 0.7811\r\n",
      "[Epoch 17/50] Train Loss: 0.3044 (Loc: 0.1948, Cls: 0.0960) | Val Loss: 0.1694 (Loc: 0.1062, Cls: 0.0548) | mAP@50: 0.8889 | mAP@50:95: 0.6227 | Precision (Avg): 0.3427 | Recall (Avg): 0.3643 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6201 | Precision: 0.7703 | Recall: 0.8294\r\n",
      "  car: mAP@50:95: 0.6883 | Precision: 0.6477 | Recall: 0.6673\r\n",
      "  motorbike: mAP@50:95: 0.5647 | Precision: 0.5948 | Recall: 0.6289\r\n",
      "  truck: mAP@50:95: 0.6176 | Precision: 0.7283 | Recall: 0.7886\r\n",
      "[Epoch 18/50] Train Loss: 0.3016 (Loc: 0.1934, Cls: 0.0948) | Val Loss: 0.1659 (Loc: 0.1034, Cls: 0.0542) | mAP@50: 0.8897 | mAP@50:95: 0.6270 | Precision (Avg): 0.3431 | Recall (Avg): 0.3632 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6167 | Precision: 0.7705 | Recall: 0.8245\r\n",
      "  car: mAP@50:95: 0.6929 | Precision: 0.6489 | Recall: 0.6680\r\n",
      "  motorbike: mAP@50:95: 0.5901 | Precision: 0.5951 | Recall: 0.6270\r\n",
      "  truck: mAP@50:95: 0.6083 | Precision: 0.7304 | Recall: 0.7863\r\n",
      "[Epoch 19/50] Train Loss: 0.2966 (Loc: 0.1904, Cls: 0.0931) | Val Loss: 0.1660 (Loc: 0.1035, Cls: 0.0546) | mAP@50: 0.8886 | mAP@50:95: 0.6312 | Precision (Avg): 0.3428 | Recall (Avg): 0.3642 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6223 | Precision: 0.7696 | Recall: 0.8276\r\n",
      "  car: mAP@50:95: 0.6996 | Precision: 0.6488 | Recall: 0.6683\r\n",
      "  motorbike: mAP@50:95: 0.5910 | Precision: 0.5959 | Recall: 0.6282\r\n",
      "  truck: mAP@50:95: 0.6119 | Precision: 0.7280 | Recall: 0.7891\r\n",
      "[Epoch 20/50] Train Loss: 0.2923 (Loc: 0.1881, Cls: 0.0914) | Val Loss: 0.1649 (Loc: 0.1028, Cls: 0.0541) | mAP@50: 0.8893 | mAP@50:95: 0.6332 | Precision (Avg): 0.3428 | Recall (Avg): 0.3641 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6249 | Precision: 0.7696 | Recall: 0.8260\r\n",
      "  car: mAP@50:95: 0.7012 | Precision: 0.6486 | Recall: 0.6690\r\n",
      "  motorbike: mAP@50:95: 0.5942 | Precision: 0.5952 | Recall: 0.6282\r\n",
      "  truck: mAP@50:95: 0.6125 | Precision: 0.7291 | Recall: 0.7897\r\n",
      "[Epoch 21/50] Train Loss: 0.2887 (Loc: 0.1859, Cls: 0.0903) | Val Loss: 0.1649 (Loc: 0.1022, Cls: 0.0547) | mAP@50: 0.8946 | mAP@50:95: 0.6396 | Precision (Avg): 0.3449 | Recall (Avg): 0.3644 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6345 | Precision: 0.7781 | Recall: 0.8299\r\n",
      "  car: mAP@50:95: 0.7012 | Precision: 0.6490 | Recall: 0.6674\r\n",
      "  motorbike: mAP@50:95: 0.5948 | Precision: 0.5952 | Recall: 0.6268\r\n",
      "  truck: mAP@50:95: 0.6281 | Precision: 0.7368 | Recall: 0.7910\r\n",
      "[Epoch 22/50] Train Loss: 0.2851 (Loc: 0.1840, Cls: 0.0889) | Val Loss: 0.1641 (Loc: 0.1021, Cls: 0.0540) | mAP@50: 0.8923 | mAP@50:95: 0.6353 | Precision (Avg): 0.3439 | Recall (Avg): 0.3649 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6271 | Precision: 0.7719 | Recall: 0.8306\r\n",
      "  car: mAP@50:95: 0.7022 | Precision: 0.6493 | Recall: 0.6688\r\n",
      "  motorbike: mAP@50:95: 0.5901 | Precision: 0.5955 | Recall: 0.6267\r\n",
      "  truck: mAP@50:95: 0.6216 | Precision: 0.7344 | Recall: 0.7932\r\n",
      "[Epoch 23/50] Train Loss: 0.2820 (Loc: 0.1823, Cls: 0.0877) | Val Loss: 0.1628 (Loc: 0.1017, Cls: 0.0532) | mAP@50: 0.8942 | mAP@50:95: 0.6384 | Precision (Avg): 0.3449 | Recall (Avg): 0.3648 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6356 | Precision: 0.7803 | Recall: 0.8326\r\n",
      "  car: mAP@50:95: 0.7016 | Precision: 0.6501 | Recall: 0.6697\r\n",
      "  motorbike: mAP@50:95: 0.5971 | Precision: 0.5979 | Recall: 0.6292\r\n",
      "  truck: mAP@50:95: 0.6195 | Precision: 0.7306 | Recall: 0.7866\r\n",
      "[Epoch 24/50] Train Loss: 0.2786 (Loc: 0.1805, Cls: 0.0863) | Val Loss: 0.1610 (Loc: 0.1002, Cls: 0.0529) | mAP@50: 0.8962 | mAP@50:95: 0.6433 | Precision (Avg): 0.3453 | Recall (Avg): 0.3648 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6375 | Precision: 0.7784 | Recall: 0.8290\r\n",
      "  car: mAP@50:95: 0.7070 | Precision: 0.6507 | Recall: 0.6691\r\n",
      "  motorbike: mAP@50:95: 0.5975 | Precision: 0.5983 | Recall: 0.6299\r\n",
      "  truck: mAP@50:95: 0.6313 | Precision: 0.7348 | Recall: 0.7902\r\n",
      "[Epoch 25/50] Train Loss: 0.2755 (Loc: 0.1787, Cls: 0.0853) | Val Loss: 0.1612 (Loc: 0.1001, Cls: 0.0534) | mAP@50: 0.8939 | mAP@50:95: 0.6413 | Precision (Avg): 0.3446 | Recall (Avg): 0.3643 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6379 | Precision: 0.7787 | Recall: 0.8310\r\n",
      "  car: mAP@50:95: 0.7102 | Precision: 0.6506 | Recall: 0.6690\r\n",
      "  motorbike: mAP@50:95: 0.5927 | Precision: 0.5967 | Recall: 0.6258\r\n",
      "  truck: mAP@50:95: 0.6244 | Precision: 0.7306 | Recall: 0.7889\r\n",
      "[Epoch 26/50] Train Loss: 0.2735 (Loc: 0.1774, Cls: 0.0849) | Val Loss: 0.1590 (Loc: 0.0986, Cls: 0.0527) | mAP@50: 0.8959 | mAP@50:95: 0.6443 | Precision (Avg): 0.3454 | Recall (Avg): 0.3646 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6364 | Precision: 0.7796 | Recall: 0.8316\r\n",
      "  car: mAP@50:95: 0.7133 | Precision: 0.6508 | Recall: 0.6693\r\n",
      "  motorbike: mAP@50:95: 0.5984 | Precision: 0.5977 | Recall: 0.6292\r\n",
      "  truck: mAP@50:95: 0.6293 | Precision: 0.7352 | Recall: 0.7867\r\n",
      "[Epoch 27/50] Train Loss: 0.2700 (Loc: 0.1757, Cls: 0.0833) | Val Loss: 0.1616 (Loc: 0.1001, Cls: 0.0539) | mAP@50: 0.8966 | mAP@50:95: 0.6416 | Precision (Avg): 0.3454 | Recall (Avg): 0.3650 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6329 | Precision: 0.7784 | Recall: 0.8290\r\n",
      "  car: mAP@50:95: 0.7079 | Precision: 0.6502 | Recall: 0.6676\r\n",
      "  motorbike: mAP@50:95: 0.5962 | Precision: 0.5988 | Recall: 0.6299\r\n",
      "  truck: mAP@50:95: 0.6295 | Precision: 0.7357 | Recall: 0.7938\r\n",
      "[Epoch 28/50] Train Loss: 0.2679 (Loc: 0.1744, Cls: 0.0826) | Val Loss: 0.1616 (Loc: 0.1001, Cls: 0.0539) | mAP@50: 0.8959 | mAP@50:95: 0.6451 | Precision (Avg): 0.3453 | Recall (Avg): 0.3636 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6406 | Precision: 0.7771 | Recall: 0.8267\r\n",
      "  car: mAP@50:95: 0.7112 | Precision: 0.6512 | Recall: 0.6676\r\n",
      "  motorbike: mAP@50:95: 0.5941 | Precision: 0.5990 | Recall: 0.6287\r\n",
      "  truck: mAP@50:95: 0.6343 | Precision: 0.7351 | Recall: 0.7862\r\n",
      "[Epoch 29/50] Train Loss: 0.2652 (Loc: 0.1728, Cls: 0.0816) | Val Loss: 0.1603 (Loc: 0.0988, Cls: 0.0537) | mAP@50: 0.8982 | mAP@50:95: 0.6488 | Precision (Avg): 0.3462 | Recall (Avg): 0.3648 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6422 | Precision: 0.7820 | Recall: 0.8310\r\n",
      "  car: mAP@50:95: 0.7141 | Precision: 0.6516 | Recall: 0.6691\r\n",
      "  motorbike: mAP@50:95: 0.6013 | Precision: 0.5978 | Recall: 0.6273\r\n",
      "  truck: mAP@50:95: 0.6374 | Precision: 0.7382 | Recall: 0.7906\r\n",
      "[Epoch 30/50] Train Loss: 0.2627 (Loc: 0.1714, Cls: 0.0807) | Val Loss: 0.1604 (Loc: 0.0994, Cls: 0.0535) | mAP@50: 0.8949 | mAP@50:95: 0.6455 | Precision (Avg): 0.3451 | Recall (Avg): 0.3635 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6368 | Precision: 0.7810 | Recall: 0.8273\r\n",
      "  car: mAP@50:95: 0.7164 | Precision: 0.6510 | Recall: 0.6679\r\n",
      "  motorbike: mAP@50:95: 0.6028 | Precision: 0.5972 | Recall: 0.6259\r\n",
      "  truck: mAP@50:95: 0.6260 | Precision: 0.7319 | Recall: 0.7867\r\n",
      "[Epoch 31/50] Train Loss: 0.2609 (Loc: 0.1703, Cls: 0.0801) | Val Loss: 0.1623 (Loc: 0.1008, Cls: 0.0539) | mAP@50: 0.8960 | mAP@50:95: 0.6431 | Precision (Avg): 0.3455 | Recall (Avg): 0.3642 | LR: 0.000100\r\n",
      "  bus: mAP@50:95: 0.6437 | Precision: 0.7816 | Recall: 0.8277\r\n",
      "  car: mAP@50:95: 0.7125 | Precision: 0.6508 | Recall: 0.6694\r\n",
      "  motorbike: mAP@50:95: 0.5919 | Precision: 0.5976 | Recall: 0.6280\r\n",
      "  truck: mAP@50:95: 0.6244 | Precision: 0.7339 | Recall: 0.7886\r\n",
      "[Epoch 32/50] Train Loss: 0.2577 (Loc: 0.1686, Cls: 0.0789) | Val Loss: 0.1596 (Loc: 0.0988, Cls: 0.0532) | mAP@50: 0.8971 | mAP@50:95: 0.6479 | Precision (Avg): 0.3459 | Recall (Avg): 0.3651 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6376 | Precision: 0.7758 | Recall: 0.8306\r\n",
      "  car: mAP@50:95: 0.7150 | Precision: 0.6509 | Recall: 0.6696\r\n",
      "  motorbike: mAP@50:95: 0.6005 | Precision: 0.5990 | Recall: 0.6278\r\n",
      "  truck: mAP@50:95: 0.6386 | Precision: 0.7418 | Recall: 0.7931\r\n",
      "[Epoch 33/50] Train Loss: 0.2607 (Loc: 0.1710, Cls: 0.0795) | Val Loss: 0.1566 (Loc: 0.0967, Cls: 0.0524) | mAP@50: 0.8972 | mAP@50:95: 0.6402 | Precision (Avg): 0.3458 | Recall (Avg): 0.3647 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6317 | Precision: 0.7779 | Recall: 0.8296\r\n",
      "  car: mAP@50:95: 0.7048 | Precision: 0.6513 | Recall: 0.6680\r\n",
      "  motorbike: mAP@50:95: 0.5905 | Precision: 0.5977 | Recall: 0.6283\r\n",
      "  truck: mAP@50:95: 0.6337 | Precision: 0.7393 | Recall: 0.7916\r\n",
      "[Epoch 34/50] Train Loss: 0.2606 (Loc: 0.1708, Cls: 0.0797) | Val Loss: 0.1561 (Loc: 0.0964, Cls: 0.0522) | mAP@50: 0.8942 | mAP@50:95: 0.6435 | Precision (Avg): 0.3446 | Recall (Avg): 0.3647 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6332 | Precision: 0.7733 | Recall: 0.8284\r\n",
      "  car: mAP@50:95: 0.7090 | Precision: 0.6507 | Recall: 0.6686\r\n",
      "  motorbike: mAP@50:95: 0.6015 | Precision: 0.5973 | Recall: 0.6292\r\n",
      "  truck: mAP@50:95: 0.6301 | Precision: 0.7354 | Recall: 0.7914\r\n",
      "[Epoch 35/50] Train Loss: 0.2590 (Loc: 0.1698, Cls: 0.0791) | Val Loss: 0.1559 (Loc: 0.0962, Cls: 0.0522) | mAP@50: 0.8949 | mAP@50:95: 0.6416 | Precision (Avg): 0.3453 | Recall (Avg): 0.3640 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6261 | Precision: 0.7763 | Recall: 0.8263\r\n",
      "  car: mAP@50:95: 0.7110 | Precision: 0.6487 | Recall: 0.6669\r\n",
      "  motorbike: mAP@50:95: 0.5987 | Precision: 0.5986 | Recall: 0.6288\r\n",
      "  truck: mAP@50:95: 0.6306 | Precision: 0.7386 | Recall: 0.7902\r\n",
      "[Epoch 36/50] Train Loss: 0.2582 (Loc: 0.1694, Cls: 0.0787) | Val Loss: 0.1558 (Loc: 0.0961, Cls: 0.0521) | mAP@50: 0.8979 | mAP@50:95: 0.6427 | Precision (Avg): 0.3461 | Recall (Avg): 0.3647 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6339 | Precision: 0.7777 | Recall: 0.8296\r\n",
      "  car: mAP@50:95: 0.7140 | Precision: 0.6509 | Recall: 0.6676\r\n",
      "  motorbike: mAP@50:95: 0.5909 | Precision: 0.5988 | Recall: 0.6302\r\n",
      "  truck: mAP@50:95: 0.6320 | Precision: 0.7417 | Recall: 0.7900\r\n",
      "[Epoch 37/50] Train Loss: 0.2570 (Loc: 0.1689, Cls: 0.0782) | Val Loss: 0.1557 (Loc: 0.0960, Cls: 0.0522) | mAP@50: 0.8973 | mAP@50:95: 0.6419 | Precision (Avg): 0.3460 | Recall (Avg): 0.3643 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6339 | Precision: 0.7788 | Recall: 0.8290\r\n",
      "  car: mAP@50:95: 0.7125 | Precision: 0.6509 | Recall: 0.6680\r\n",
      "  motorbike: mAP@50:95: 0.5934 | Precision: 0.5976 | Recall: 0.6280\r\n",
      "  truck: mAP@50:95: 0.6278 | Precision: 0.7410 | Recall: 0.7896\r\n",
      "[Epoch 38/50] Train Loss: 0.2543 (Loc: 0.1672, Cls: 0.0774) | Val Loss: 0.1553 (Loc: 0.0958, Cls: 0.0519) | mAP@50: 0.8964 | mAP@50:95: 0.6425 | Precision (Avg): 0.3458 | Recall (Avg): 0.3647 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6340 | Precision: 0.7780 | Recall: 0.8296\r\n",
      "  car: mAP@50:95: 0.7062 | Precision: 0.6508 | Recall: 0.6692\r\n",
      "  motorbike: mAP@50:95: 0.5991 | Precision: 0.5978 | Recall: 0.6276\r\n",
      "  truck: mAP@50:95: 0.6307 | Precision: 0.7399 | Recall: 0.7915\r\n",
      "[Epoch 39/50] Train Loss: 0.2541 (Loc: 0.1670, Cls: 0.0773) | Val Loss: 0.1555 (Loc: 0.0958, Cls: 0.0522) | mAP@50: 0.8950 | mAP@50:95: 0.6412 | Precision (Avg): 0.3449 | Recall (Avg): 0.3639 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6279 | Precision: 0.7761 | Recall: 0.8293\r\n",
      "  car: mAP@50:95: 0.7141 | Precision: 0.6515 | Recall: 0.6684\r\n",
      "  motorbike: mAP@50:95: 0.5937 | Precision: 0.5976 | Recall: 0.6265\r\n",
      "  truck: mAP@50:95: 0.6290 | Precision: 0.7340 | Recall: 0.7872\r\n",
      "[Epoch 40/50] Train Loss: 0.2533 (Loc: 0.1666, Cls: 0.0769) | Val Loss: 0.1555 (Loc: 0.0959, Cls: 0.0521) | mAP@50: 0.8958 | mAP@50:95: 0.6439 | Precision (Avg): 0.3452 | Recall (Avg): 0.3639 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6293 | Precision: 0.7753 | Recall: 0.8243\r\n",
      "  car: mAP@50:95: 0.7134 | Precision: 0.6513 | Recall: 0.6687\r\n",
      "  motorbike: mAP@50:95: 0.5989 | Precision: 0.5974 | Recall: 0.6288\r\n",
      "  truck: mAP@50:95: 0.6342 | Precision: 0.7380 | Recall: 0.7894\r\n",
      "[Epoch 41/50] Train Loss: 0.2519 (Loc: 0.1658, Cls: 0.0766) | Val Loss: 0.1555 (Loc: 0.0957, Cls: 0.0522) | mAP@50: 0.8935 | mAP@50:95: 0.6399 | Precision (Avg): 0.3451 | Recall (Avg): 0.3633 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6268 | Precision: 0.7757 | Recall: 0.8260\r\n",
      "  car: mAP@50:95: 0.7128 | Precision: 0.6494 | Recall: 0.6675\r\n",
      "  motorbike: mAP@50:95: 0.5912 | Precision: 0.5982 | Recall: 0.6266\r\n",
      "  truck: mAP@50:95: 0.6290 | Precision: 0.7372 | Recall: 0.7860\r\n",
      "[Epoch 42/50] Train Loss: 0.2512 (Loc: 0.1654, Cls: 0.0763) | Val Loss: 0.1555 (Loc: 0.0958, Cls: 0.0522) | mAP@50: 0.8933 | mAP@50:95: 0.6409 | Precision (Avg): 0.3447 | Recall (Avg): 0.3634 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6257 | Precision: 0.7753 | Recall: 0.8256\r\n",
      "  car: mAP@50:95: 0.7136 | Precision: 0.6492 | Recall: 0.6674\r\n",
      "  motorbike: mAP@50:95: 0.5974 | Precision: 0.5971 | Recall: 0.6269\r\n",
      "  truck: mAP@50:95: 0.6270 | Precision: 0.7362 | Recall: 0.7875\r\n",
      "[Epoch 43/50] Train Loss: 0.2498 (Loc: 0.1648, Cls: 0.0755) | Val Loss: 0.1550 (Loc: 0.0956, Cls: 0.0520) | mAP@50: 0.8929 | mAP@50:95: 0.6378 | Precision (Avg): 0.3446 | Recall (Avg): 0.3638 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6164 | Precision: 0.7698 | Recall: 0.8258\r\n",
      "  car: mAP@50:95: 0.7079 | Precision: 0.6500 | Recall: 0.6677\r\n",
      "  motorbike: mAP@50:95: 0.5938 | Precision: 0.5950 | Recall: 0.6254\r\n",
      "  truck: mAP@50:95: 0.6330 | Precision: 0.7421 | Recall: 0.7914\r\n",
      "[Epoch 44/50] Train Loss: 0.2489 (Loc: 0.1642, Cls: 0.0752) | Val Loss: 0.1551 (Loc: 0.0956, Cls: 0.0519) | mAP@50: 0.8915 | mAP@50:95: 0.6328 | Precision (Avg): 0.3440 | Recall (Avg): 0.3628 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6241 | Precision: 0.7751 | Recall: 0.8256\r\n",
      "  car: mAP@50:95: 0.7000 | Precision: 0.6496 | Recall: 0.6673\r\n",
      "  motorbike: mAP@50:95: 0.5828 | Precision: 0.5947 | Recall: 0.6229\r\n",
      "  truck: mAP@50:95: 0.6242 | Precision: 0.7330 | Recall: 0.7864\r\n",
      "[Epoch 45/50] Train Loss: 0.2482 (Loc: 0.1638, Cls: 0.0749) | Val Loss: 0.1551 (Loc: 0.0956, Cls: 0.0520) | mAP@50: 0.8922 | mAP@50:95: 0.6373 | Precision (Avg): 0.3443 | Recall (Avg): 0.3634 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6237 | Precision: 0.7741 | Recall: 0.8259\r\n",
      "  car: mAP@50:95: 0.7097 | Precision: 0.6497 | Recall: 0.6676\r\n",
      "  motorbike: mAP@50:95: 0.5920 | Precision: 0.5961 | Recall: 0.6253\r\n",
      "  truck: mAP@50:95: 0.6240 | Precision: 0.7346 | Recall: 0.7881\r\n",
      "[Epoch 46/50] Train Loss: 0.2465 (Loc: 0.1630, Cls: 0.0743) | Val Loss: 0.1552 (Loc: 0.0955, Cls: 0.0521) | mAP@50: 0.8924 | mAP@50:95: 0.6377 | Precision (Avg): 0.3444 | Recall (Avg): 0.3631 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6274 | Precision: 0.7770 | Recall: 0.8273\r\n",
      "  car: mAP@50:95: 0.7086 | Precision: 0.6497 | Recall: 0.6673\r\n",
      "  motorbike: mAP@50:95: 0.5873 | Precision: 0.5940 | Recall: 0.6236\r\n",
      "  truck: mAP@50:95: 0.6277 | Precision: 0.7347 | Recall: 0.7867\r\n",
      "[Epoch 47/50] Train Loss: 0.2457 (Loc: 0.1624, Cls: 0.0742) | Val Loss: 0.1550 (Loc: 0.0954, Cls: 0.0520) | mAP@50: 0.8943 | mAP@50:95: 0.6377 | Precision (Avg): 0.3452 | Recall (Avg): 0.3635 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6256 | Precision: 0.7757 | Recall: 0.8262\r\n",
      "  car: mAP@50:95: 0.7105 | Precision: 0.6513 | Recall: 0.6687\r\n",
      "  motorbike: mAP@50:95: 0.5886 | Precision: 0.5962 | Recall: 0.6250\r\n",
      "  truck: mAP@50:95: 0.6259 | Precision: 0.7382 | Recall: 0.7886\r\n",
      "[Epoch 48/50] Train Loss: 0.2454 (Loc: 0.1621, Cls: 0.0741) | Val Loss: 0.1549 (Loc: 0.0955, Cls: 0.0518) | mAP@50: 0.8931 | mAP@50:95: 0.6381 | Precision (Avg): 0.3447 | Recall (Avg): 0.3639 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6208 | Precision: 0.7732 | Recall: 0.8275\r\n",
      "  car: mAP@50:95: 0.7103 | Precision: 0.6505 | Recall: 0.6684\r\n",
      "  motorbike: mAP@50:95: 0.5895 | Precision: 0.5957 | Recall: 0.6258\r\n",
      "  truck: mAP@50:95: 0.6316 | Precision: 0.7380 | Recall: 0.7899\r\n",
      "[Epoch 49/50] Train Loss: 0.2447 (Loc: 0.1618, Cls: 0.0739) | Val Loss: 0.1550 (Loc: 0.0955, Cls: 0.0520) | mAP@50: 0.8918 | mAP@50:95: 0.6397 | Precision (Avg): 0.3443 | Recall (Avg): 0.3625 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6252 | Precision: 0.7731 | Recall: 0.8233\r\n",
      "  car: mAP@50:95: 0.7088 | Precision: 0.6491 | Recall: 0.6663\r\n",
      "  motorbike: mAP@50:95: 0.5931 | Precision: 0.5922 | Recall: 0.6225\r\n",
      "  truck: mAP@50:95: 0.6316 | Precision: 0.7399 | Recall: 0.7881\r\n",
      "[Epoch 50/50] Train Loss: 0.2432 (Loc: 0.1609, Cls: 0.0734) | Val Loss: 0.1549 (Loc: 0.0954, Cls: 0.0520) | mAP@50: 0.8903 | mAP@50:95: 0.6335 | Precision (Avg): 0.3437 | Recall (Avg): 0.3622 | LR: 0.000010\r\n",
      "  bus: mAP@50:95: 0.6232 | Precision: 0.7752 | Recall: 0.8242\r\n",
      "  car: mAP@50:95: 0.7032 | Precision: 0.6481 | Recall: 0.6648\r\n",
      "  motorbike: mAP@50:95: 0.5810 | Precision: 0.5904 | Recall: 0.6217\r\n",
      "  truck: mAP@50:95: 0.6266 | Precision: 0.7356 | Recall: 0.7872\r\n"
     ]
    }
   ],
   "source": [
    "!python ddp.py"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6480498,
     "sourceId": 11027114,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18714.963695,
   "end_time": "2025-03-14T15:21:50.738383",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-14T10:09:55.774688",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
